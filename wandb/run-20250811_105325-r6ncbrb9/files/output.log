Training Configuration:
----------------------------------------
substrate_name      : commons_harvest__open
num_players         : 7
model_type          : attention_influence
feature_dim         : None
action_dim          : None
hidden_dim          : 256
num_episodes        : 5000
lr                  : 0.0003
gamma               : 0.99
eps_clip            : 0.2
k_epochs            : 4
influence_weight    : 0.1
curriculum_steps    : 1000000
device              : cuda
save_interval       : 500
log_interval        : 10
use_wandb           : True
wandb_project       : item-aware-social-influence
wandb_entity        : None
----------------------------------------
================================================================================
Starting training: attention_influence on commons_harvest__open
================================================================================
Creating environment: commons_harvest__open
[DEBUG] Using roles: ['default', 'default', 'default', 'default', 'default', 'default', 'default']
Structured feature dimension: 20
Number of players: 7

=== OBSERVATION DEBUG ===
Observation type: <class 'dict'>
Observation keys: ['COLLECTIVE_REWARD', 'READY_TO_SHOOT', 'RGB', 'WORLD.RGB']
  COLLECTIVE_REWARD: shape (), dtype float64
  READY_TO_SHOOT: shape (), dtype float64
  RGB: shape (88, 88, 3), dtype uint8
  WORLD.RGB: shape (144, 192, 3), dtype uint8
=========================


=== ENVIRONMENT VALIDATION ===
Reset observation type: <class 'dict'>
Number of agents: 7
First agent observation type: <class 'dict'>
✓ Structured features extracted: 20 dimensions
✓ Item positions extracted: (0, 2)
==============================

Creating attention_influence trainer...
Feature dim: 20, Action dim: 8
Starting training for 5000 episodes...
/home/kaou-internship/meltingpot/examples/rllib/attention_influence_ppo.py:478: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  neighbor_positions_tensor = torch.FloatTensor(neighbor_positions).to(self.device)
Input shapes - my_features: torch.Size([1, 156]), neighbors: torch.Size([6, 2]), items: torch.Size([0, 2])
Attention outputs - context: torch.Size([64]), mean_item: torch.Size([64])
Combined features shape: torch.Size([1, 284])
Error in episode 0: mat1 and mat2 shapes cannot be multiplied (1x284 and 148x256)
Continuing training...
Input shapes - my_features: torch.Size([1, 156]), neighbors: torch.Size([6, 2]), items: torch.Size([0, 2])
Attention outputs - context: torch.Size([64]), mean_item: torch.Size([64])
Combined features shape: torch.Size([1, 284])
Error in episode 1: mat1 and mat2 shapes cannot be multiplied (1x284 and 148x256)
Continuing training...
Input shapes - my_features: torch.Size([1, 156]), neighbors: torch.Size([6, 2]), items: torch.Size([0, 2])
Attention outputs - context: torch.Size([64]), mean_item: torch.Size([64])
Combined features shape: torch.Size([1, 284])
Error in episode 2: mat1 and mat2 shapes cannot be multiplied (1x284 and 148x256)
Continuing training...

Training interrupted by user
